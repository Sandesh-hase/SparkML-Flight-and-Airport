{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning with Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a tutorial of machine learning with PySpark. I will create a classification model and a regression model using Pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Spark\n",
    "Uncommet the code below to install PySpark and sparkmagic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sparkmagic\n",
    "#!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Spark SQL and Spark ML Libraries\n",
    "\n",
    "We'll train a **LogisticRegression** model with a **Pipleline** preparing the data, a **CrossValidator** to tuene the parameters of the model, and a **BinaryClassificationEvaluator** to evaluate our trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "#from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, VectorIndexer, MinMaxScaler\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-BCSH3BL:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2891c1e56d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Source Data\n",
    "The data from the flight.csv file data includes specific characteristics (or features) for each flight, as well as a column indicating how many minutes late or early the flight arrived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['airports.csv', 'flights.csv', 'raw-flight-data.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"./dataset\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|ArrDelay|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "|        19|        5|     DL|          11433|        13303|      -3|       1|\n",
      "|        19|        5|     DL|          14869|        12478|       0|      -8|\n",
      "|        19|        5|     DL|          14057|        14869|      -4|     -15|\n",
      "|        19|        5|     DL|          15016|        11433|      28|      24|\n",
      "|        19|        5|     DL|          11193|        12892|      -6|     -11|\n",
      "|        19|        5|     DL|          10397|        15016|      -1|     -19|\n",
      "|        19|        5|     DL|          15016|        10397|       0|      -1|\n",
      "|        19|        5|     DL|          10397|        14869|      15|      24|\n",
      "|        19|        5|     DL|          10397|        10423|      33|      34|\n",
      "|        19|        5|     DL|          11278|        10397|     323|     322|\n",
      "+----------+---------+-------+---------------+-------------+--------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv = spark.read.csv('./dataset/flights.csv', inferSchema=True, header=True)\n",
    "csv.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Data for a Classification Model (Decision Tree Learning Model)\n",
    "I select a subset of columns to use as features and create a Boolean label field named *label* with values 1 or 0. Specifically, **1** for flight that arrived late, **0** for flight was early or on-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+-------+---------------+-------------+--------+-----+\n",
      "|DayofMonth|DayOfWeek|Carrier|OriginAirportID|DestAirportID|DepDelay|label|\n",
      "+----------+---------+-------+---------------+-------------+--------+-----+\n",
      "|        19|        5|     DL|          11433|        13303|      -3|    0|\n",
      "|        19|        5|     DL|          14869|        12478|       0|    0|\n",
      "|        19|        5|     DL|          14057|        14869|      -4|    0|\n",
      "|        19|        5|     DL|          15016|        11433|      28|    1|\n",
      "|        19|        5|     DL|          11193|        12892|      -6|    0|\n",
      "|        19|        5|     DL|          10397|        15016|      -1|    0|\n",
      "|        19|        5|     DL|          15016|        10397|       0|    0|\n",
      "|        19|        5|     DL|          10397|        14869|      15|    1|\n",
      "|        19|        5|     DL|          10397|        10423|      33|    1|\n",
      "|        19|        5|     DL|          11278|        10397|     323|    1|\n",
      "+----------+---------+-------+---------------+-------------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = csv.select(\"DayofMonth\", \"DayOfWeek\", \"Carrier\", \"OriginAirportID\", \"DestAirportID\", \"DepDelay\", ((col(\"ArrDelay\") > 15).cast(\"Int\").alias(\"label\")))\n",
    "data.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Data\n",
    "\n",
    "I will use 70% of the data for training, and reserve 30% for testing. In the testing data, the *label* column is renamed to *trueLabel* so I can use it later to compare predicted labels with known actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Rows: 1892126  Testing Rows: 810092\n"
     ]
    }
   ],
   "source": [
    "splits = data.randomSplit([0.7, 0.3])\n",
    "train = splits[0]\n",
    "test = splits[1].withColumnRenamed(\"label\", \"trueLabel\")\n",
    "train_rows = train.count()\n",
    "test_rows = test.count()\n",
    "print(\"Training Rows:\", train_rows, \" Testing Rows:\", test_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Pipeline\n",
    "\n",
    "A pipeline consists of a series of transformer and estimator stages that typically prepare a DataFrame for modeling and then train a predictive model. In this case, you will create a pipeline with seven stages:\n",
    "* A **StringIndexer estimator** that converts string values to indexes for categorical features\n",
    "* A **VectorAssembler** that combines categorical features into a single vector\n",
    "* A **VectorIndexer** that creates indexes for a vector of categorical features\n",
    "* A **VectorAssembler** that creates a vector of continuous numeric features\n",
    "* A **MinMaxScaler** that normalizes continuous numeric features\n",
    "* A **VectorAssembler** that creates a vector of categorical and continuous features\n",
    "* A **DecisionTreeClassifier** that trains a classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "strIdx = StringIndexer(inputCol = \"Carrier\", outputCol = \"CarrierIdx\")\n",
    "catVect = VectorAssembler(inputCols = [\"CarrierIdx\", \"DayofMonth\", \"DayOfWeek\", \"OriginAirportID\", \"DestAirportID\"], outputCol=\"catFeatures\")\n",
    "catIdx = VectorIndexer(inputCol = catVect.getOutputCol(), outputCol = \"idxCatFeatures\")\n",
    "numVect = VectorAssembler(inputCols = [\"DepDelay\"], outputCol=\"numFeatures\")\n",
    "minMax = MinMaxScaler(inputCol = numVect.getOutputCol(), outputCol=\"normFeatures\")\n",
    "featVect = VectorAssembler(inputCols=[\"idxCatFeatures\", \"normFeatures\"], outputCol=\"features\")\n",
    "lr = LogisticRegression(labelCol=\"label\",featuresCol=\"features\",maxIter=10,regParam=0.3)\n",
    "#dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "pipeline = Pipeline(stages=[strIdx, catVect, catIdx, numVect, minMax, featVect, lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Pipeline to train a model\n",
    "Run the pipeline as an Estimator on the training data to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "piplineModel = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate label predictions\n",
    "Transform the test data with all of the stages and the trained model in the pipeline to generate label predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------+----------+---------+\n",
      "|features                                           |prediction|trueLabel|\n",
      "+---------------------------------------------------+----------+---------+\n",
      "|[10.0,1.0,0.0,10397.0,12264.0,0.030114226375908618]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,10397.0,12264.0,0.04465212876427829] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,10423.0,13487.0,0.029595015576323987]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,10693.0,11193.0,0.03115264797507788] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,10721.0,12478.0,0.03115264797507788] |0.0       |1        |\n",
      "|[10.0,1.0,0.0,10721.0,12478.0,0.03686396677050883] |0.0       |1        |\n",
      "|[10.0,1.0,0.0,10721.0,12478.0,0.04569055036344756] |0.0       |1        |\n",
      "|[10.0,1.0,0.0,10792.0,11433.0,0.03686396677050883] |0.0       |1        |\n",
      "|[10.0,1.0,0.0,10821.0,11193.0,0.027518172377985463]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,10821.0,12478.0,0.027518172377985463]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,10821.0,12478.0,0.029595015576323987]|0.0       |1        |\n",
      "|[10.0,1.0,0.0,10821.0,12478.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,10821.0,13487.0,0.029075804776739357]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11042.0,11433.0,0.028556593977154723]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11042.0,11433.0,0.029075804776739357]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11057.0,12478.0,0.03115264797507788] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11057.0,13244.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11057.0,13244.0,0.03115264797507788] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11066.0,13487.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11066.0,13487.0,0.03115264797507788] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11193.0,10693.0,0.049325025960539975]|0.0       |1        |\n",
      "|[10.0,1.0,0.0,11193.0,11433.0,0.027518172377985463]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11193.0,11433.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11193.0,11618.0,0.06438213914849429] |0.0       |1        |\n",
      "|[10.0,1.0,0.0,11193.0,12451.0,0.11163032191069575] |1.0       |1        |\n",
      "|[10.0,1.0,0.0,11193.0,13198.0,0.027518172377985463]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11193.0,13487.0,0.029075804776739357]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11193.0,13487.0,0.029595015576323987]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11193.0,13487.0,0.030114226375908618]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11193.0,13487.0,0.03115264797507788] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11193.0,13930.0,0.030114226375908618]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11193.0,13930.0,0.07217030114226376] |0.0       |1        |\n",
      "|[10.0,1.0,0.0,11193.0,14100.0,0.029595015576323987]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11193.0,14492.0,0.04620976116303219] |0.0       |1        |\n",
      "|[10.0,1.0,0.0,11193.0,15016.0,0.028556593977154723]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11193.0,15016.0,0.03115264797507788] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11278.0,12478.0,0.035306334371754934]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11278.0,13244.0,0.04672897196261682] |0.0       |1        |\n",
      "|[10.0,1.0,0.0,11433.0,10693.0,0.03271028037383177] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,10693.0,0.03790238836967809] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,10792.0,0.03115264797507788] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,11042.0,0.028556593977154723]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,11193.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,11193.0,0.032191069574247146]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,11193.0,0.03686396677050883] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,11278.0,0.032191069574247146]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,11298.0,0.03167185877466251] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,12339.0,0.029595015576323987]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,12339.0,0.03686396677050883] |0.0       |1        |\n",
      "|[10.0,1.0,0.0,11433.0,13232.0,0.028556593977154723]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,13232.0,0.03167185877466251] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,13342.0,0.0347871235721703]  |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,13871.0,0.035306334371754934]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,13930.0,0.036344755970924195]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,14100.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,14100.0,0.037383177570093455]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,14100.0,0.03790238836967809] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,14122.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,14307.0,0.03271028037383177] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,14492.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,14492.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,11433.0,14524.0,0.03115264797507788] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,12264.0,10397.0,0.032191069574247146]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,12266.0,13244.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,12339.0,11433.0,0.02699896157840083] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,12339.0,11433.0,0.027518172377985463]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,12339.0,11433.0,0.029595015576323987]|0.0       |1        |\n",
      "|[10.0,1.0,0.0,12339.0,11433.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,12339.0,13487.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,12451.0,11433.0,0.03115264797507788] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,12451.0,12478.0,0.0960539979231568]  |1.0       |1        |\n",
      "|[10.0,1.0,0.0,12478.0,10821.0,0.07424714434060228] |0.0       |1        |\n",
      "|[10.0,1.0,0.0,12478.0,11278.0,0.03167185877466251] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,12478.0,11433.0,0.03686396677050883] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,12478.0,12451.0,0.04361370716510903] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,12478.0,13487.0,0.06542056074766354] |0.0       |1        |\n",
      "|[10.0,1.0,0.0,12478.0,13930.0,0.03271028037383177] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,12478.0,13931.0,0.030114226375908618]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,12478.0,14100.0,0.03115264797507788] |0.0       |1        |\n",
      "|[10.0,1.0,0.0,12478.0,14100.0,0.03271028037383177] |0.0       |1        |\n",
      "|[10.0,1.0,0.0,12478.0,14122.0,0.0264797507788162]  |0.0       |0        |\n",
      "|[10.0,1.0,0.0,12478.0,14122.0,0.04465212876427829] |0.0       |1        |\n",
      "|[10.0,1.0,0.0,12478.0,14492.0,0.028556593977154723]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,12478.0,14492.0,0.032191069574247146]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,13198.0,11193.0,0.04361370716510903] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,13198.0,12478.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,13204.0,14492.0,0.142263759086189]   |1.0       |1        |\n",
      "|[10.0,1.0,0.0,13232.0,11433.0,0.03115264797507788] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,13232.0,13487.0,0.030633437175493248]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,13244.0,11193.0,0.030114226375908618]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,13244.0,11193.0,0.03271028037383177] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,13244.0,11278.0,0.048286604361370715]|0.0       |1        |\n",
      "|[10.0,1.0,0.0,13244.0,12339.0,0.02596053997923157] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,13244.0,13198.0,0.03115264797507788] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,13244.0,13495.0,0.032191069574247146]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,13244.0,14100.0,0.030114226375908618]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,13244.0,14683.0,0.030114226375908618]|0.0       |0        |\n",
      "|[10.0,1.0,0.0,13244.0,14683.0,0.18016614745586707] |1.0       |1        |\n",
      "|[10.0,1.0,0.0,13244.0,14869.0,0.03115264797507788] |0.0       |0        |\n",
      "|[10.0,1.0,0.0,13487.0,10423.0,0.03271028037383177] |0.0       |0        |\n",
      "+---------------------------------------------------+----------+---------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = piplineModel.transform(test)\n",
    "predicted = prediction.select(\"features\", \"prediction\", \"trueLabel\")\n",
    "predicted.show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking into the results, some trueLabel 1s are predicted as 0. Let's evaluate the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating a Classification Model\n",
    "We'll calculate a *Confusion Matrix* and the *Area Under ROC* (Receiver Operating Characteristic) to evaluate the model. \n",
    "### Compute Confusion Matrix\n",
    "Classifiers are typically evaluated by creating a *confusion matrix*, which indicates the number of:\n",
    "- True Positives\n",
    "- True Negatives\n",
    "- False Positives\n",
    "- False Negatives\n",
    "\n",
    "From these core measures, other evaluation metrics such as *precision*, *recall* and *F1* can be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TP</td>\n",
       "      <td>19183.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FP</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TN</td>\n",
       "      <td>648693.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FN</td>\n",
       "      <td>142122.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.995124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.118924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F1</td>\n",
       "      <td>0.212457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metric          value\n",
       "0         TP   19183.000000\n",
       "1         FP      94.000000\n",
       "2         TN  648693.000000\n",
       "3         FN  142122.000000\n",
       "4  Precision       0.995124\n",
       "5     Recall       0.118924\n",
       "6         F1       0.212457"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp = float(predicted.filter(\"prediction == 1.0 AND truelabel == 1\").count())\n",
    "fp = float(predicted.filter(\"prediction == 1.0 AND truelabel == 0\").count())\n",
    "tn = float(predicted.filter(\"prediction == 0.0 AND truelabel == 0\").count())\n",
    "fn = float(predicted.filter(\"prediction == 0.0 AND truelabel == 1\").count())\n",
    "pr = tp / (tp + fp)\n",
    "re = tp / (tp + fn)\n",
    "# metrics = spark.createDataFrame([\n",
    "#  (\"TP\", tp),\n",
    "#  (\"FP\", fp),\n",
    "#  (\"TN\", tn),\n",
    "#  (\"FN\", fn),\n",
    "#  (\"Precision\", pr),\n",
    "#  (\"Recall\", re),\n",
    "#  (\"F1\", 2*pr*re/(re+pr))],[\"metric\", \"value\"])\n",
    "# metrics.show()\n",
    "\n",
    "#### Spark data frame is not printing hence used pandas data frame\n",
    "data = [\n",
    " (\"TP\", tp),\n",
    " (\"FP\", fp),\n",
    " (\"TN\", tn),\n",
    " (\"FN\", fn),\n",
    " (\"Precision\", pr),\n",
    " (\"Recall\", re),\n",
    " (\"F1\", 2*pr*re/(re+pr))]\n",
    "columns = [\"metric\", \"value\"]\n",
    "pandas_df = pd.DataFrame(data = data, columns = columns)\n",
    "pandas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we've got a good *Precision*, but a low *Recall*, therefore our *F1* is not that good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the Area Under ROC\n",
    "Another way to assess the performance of a classification model is to measure the area under a ROC (Receiver Operating Characteristic) curve for the model. the spark.ml library includes a **BinaryClassificationEvaluator** class that we can use to compute this. The ROC curve shows the True Positive and False Positive rates plotted for varying thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUR =  0.9218253010098655\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=\"trueLabel\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "aur = evaluator.evaluate(prediction)\n",
    "print (\"AUR = \", aur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the AUR shows that our model is ok.\n",
    "Let's look deeper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the Raw Prediction and Probability\n",
    "The prediction is based on a raw prediction score that describes a labelled point in a logistic function. This raw prediction is then converted to a predicted label of 0 or 1 based on a probability vector that indicates the confidence for each possible label value (in this case, 0 and 1). The value with the highest confidence is selected as the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+----------------------------------------+----------+---------+\n",
      "|rawPrediction                             |probability                             |prediction|trueLabel|\n",
      "+------------------------------------------+----------------------------------------+----------+---------+\n",
      "|[1.6257905436467905,-1.6257905436467905]  |[0.835592169140788,0.16440783085921196] |0.0       |0        |\n",
      "|[1.2340336076017322,-1.2340336076017322]  |[0.774523770110834,0.22547622988916605] |0.0       |0        |\n",
      "|[1.6407408902007221,-1.6407408902007221]  |[0.8376357252626556,0.16236427473734438]|0.0       |0        |\n",
      "|[1.5996697784054876,-1.5996697784054876]  |[0.8319722270513612,0.1680277729486388] |0.0       |0        |\n",
      "|[1.600683203383918,-1.600683203383918]    |[0.8321138505708031,0.16788614942919688]|0.0       |1        |\n",
      "|[1.4467786927947879,-1.4467786927947879]  |[0.8095021765445082,0.19049782345549182]|0.0       |1        |\n",
      "|[1.2089262673388594,-1.2089262673388594]  |[0.7701089092868506,0.2298910907131494] |0.0       |1        |\n",
      "|[1.446749292450034,-1.446749292450034]    |[0.8094976427230494,0.19050235727695064]|0.0       |1        |\n",
      "|[1.6986938703478673,-1.6986938703478673]  |[0.8453640698784982,0.15463593012150179]|0.0       |0        |\n",
      "|[1.6994699826538664,-1.6994699826538664]  |[0.8454654989268515,0.15453450107314848]|0.0       |0        |\n",
      "|[1.6435047060760009,-1.6435047060760009]  |[0.838011259399163,0.161988740600837]   |0.0       |1        |\n",
      "|[1.6155220677870683,-1.6155220677870683]  |[0.8341766420350261,0.16582335796497394]|0.0       |0        |\n",
      "|[1.6581054394747496,-1.6581054394747496]  |[0.8399835168826219,0.16001648311737815]|0.0       |0        |\n",
      "|[1.6727292619082053,-1.6727292619082053]  |[0.8419393634767367,0.1580606365232633] |0.0       |0        |\n",
      "|[1.6587379427637388,-1.6587379427637388]  |[0.8400685141332146,0.1599314858667854] |0.0       |0        |\n",
      "|[1.6035309554530952,-1.6035309554530952]  |[0.8325113064726143,0.1674886935273857] |0.0       |0        |\n",
      "|[1.6179849220889198,-1.6179849220889198]  |[0.8345170384220749,0.16548296157792508]|0.0       |0        |\n",
      "|[1.6039936029444535,-1.6039936029444535]  |[0.8325758063715961,0.16742419362840388]|0.0       |0        |\n",
      "|[1.6182079679251258,-1.6182079679251258]  |[0.8345478383860595,0.1654521616139405] |0.0       |0        |\n",
      "|[1.604216648780659,-1.604216648780659]    |[0.8326068951678354,0.16739310483216463]|0.0       |0        |\n",
      "|[1.1139093454184592,-1.1139093454184592]  |[0.752857215677623,0.24714278432237702] |0.0       |1        |\n",
      "|[1.7019916935377504,-1.7019916935377504]  |[0.8457946825569762,0.1542053174430238] |0.0       |0        |\n",
      "|[1.6180437786709523,-1.6180437786709523]  |[0.834525166258972,0.165474833741028]   |0.0       |0        |\n",
      "|[0.7087197702935637,-0.7087197702935637]  |[0.6701182141561893,0.32988178584381067]|0.0       |1        |\n",
      "|[-0.5639871578054856,0.5639871578054856]  |[0.362625411206653,0.6373745887933471]  |1.0       |1        |\n",
      "|[1.7030577154989084,-1.7030577154989084]  |[0.8459336683305196,0.15406633166948036]|0.0       |0        |\n",
      "|[1.6612583078370529,-1.6612583078370529]  |[0.8404068436042049,0.15959315639579508]|0.0       |0        |\n",
      "|[1.6472669886925866,-1.6472669886925866]  |[0.8385213339411773,0.16147866605882266]|0.0       |0        |\n",
      "|[1.6332756695481203,-1.6332756695481203]  |[0.8366178786688585,0.1633821213311415] |0.0       |0        |\n",
      "|[1.6052930312591875,-1.6052930312591875]  |[0.8327568597461866,0.16724314025381337]|0.0       |0        |\n",
      "|[1.6335432320006942,-1.6335432320006942]  |[0.8366544480595189,0.16334555194048106]|0.0       |0        |\n",
      "|[0.500246381298918,-0.500246381298918]    |[0.6225172299745206,0.37748277002547936]|0.0       |1        |\n",
      "|[1.6476372274813627,-1.6476372274813627]  |[0.8385714592143999,0.1614285407856001] |0.0       |0        |\n",
      "|[1.2001517744101522,-1.2001517744101522]  |[0.7685517822224263,0.23144821777757374]|0.0       |1        |\n",
      "|[1.6761731100288908,-1.6761731100288908]  |[0.8423971225738828,0.15760287742611723]|0.0       |0        |\n",
      "|[1.606216514306559,-1.606216514306559]    |[0.8328854363625767,0.16711456363742327]|0.0       |0        |\n",
      "|[1.4934734773190552,-1.4934734773190552]  |[0.816599050230346,0.18340094976965404] |0.0       |0        |\n",
      "|[1.1861271036321532,-1.1861271036321532]  |[0.7660476843567746,0.23395231564322538]|0.0       |1        |\n",
      "|[1.5636656666622237,-1.5636656666622237]  |[0.8268787231898234,0.17312127681017664]|0.0       |0        |\n",
      "|[1.42375247521756,-1.42375247521756]      |[0.8059260121954733,0.19407398780452667]|0.0       |0        |\n",
      "|[1.6056994179619994,-1.6056994179619994]  |[0.8328134507360853,0.16718654926391474]|0.0       |0        |\n",
      "|[1.6758070082963934,-1.6758070082963934]  |[0.8423485112734328,0.1576514887265672] |0.0       |0        |\n",
      "|[1.6199329324642133,-1.6199329324642133]  |[0.8347858801688774,0.16521411983112255]|0.0       |0        |\n",
      "|[1.577958975030814,-1.577958975030814]    |[0.8289152648178754,0.17108473518212464]|0.0       |0        |\n",
      "|[1.4520371027306167,-1.4520371027306167]  |[0.8103117481070108,0.1896882518929892] |0.0       |0        |\n",
      "|[1.5780103131989152,-1.5780103131989152]  |[0.8289225452043392,0.17107745479566083]|0.0       |0        |\n",
      "|[1.5920137119123468,-1.5920137119123468]  |[0.8308992296291516,0.16910077037084836]|0.0       |0        |\n",
      "|[1.6486077300548385,-1.6486077300548385]  |[0.8387027923691047,0.16129720763089528]|0.0       |0        |\n",
      "|[1.4527292620323093,-1.4527292620323093]  |[0.8104181147228569,0.18958188527714315]|0.0       |1        |\n",
      "|[1.6771297210980571,-1.6771297210980571]  |[0.8425240846922257,0.15747591530777427]|0.0       |0        |\n",
      "|[1.5931818062312588,-1.5931818062312588]  |[0.8310632901073408,0.1689367098926592] |0.0       |0        |\n",
      "|[1.5093003289937679,-1.5093003289937679]  |[0.8189574924935763,0.1810425075064237] |0.0       |0        |\n",
      "|[1.4956285144484247,-1.4956285144484247]  |[0.8169215792744166,0.18307842072558345]|0.0       |0        |\n",
      "|[1.4676815108879386,-1.4676815108879386]  |[0.8127047313040654,0.1872952686959346] |0.0       |0        |\n",
      "|[1.621688697813271,-1.621688697813271]    |[0.8350278902249474,0.1649721097750526] |0.0       |0        |\n",
      "|[1.439801548935208,-1.439801548935208]    |[0.8084239182732474,0.19157608172675256]|0.0       |0        |\n",
      "|[1.4258102297907418,-1.4258102297907418]  |[0.8062476614981442,0.1937523385018558] |0.0       |0        |\n",
      "|[1.6217019853391323,-1.6217019853391323]  |[0.8350297206573674,0.16497027934263264]|0.0       |0        |\n",
      "|[1.565848444774193,-1.565848444774193]    |[0.8271909656219849,0.1728090343780151] |0.0       |0        |\n",
      "|[1.6219254573649842,-1.6219254573649842]  |[0.8350605027607917,0.1649394972392083] |0.0       |0        |\n",
      "|[1.6219254573649842,-1.6219254573649842]  |[0.8350605027607917,0.1649394972392083] |0.0       |0        |\n",
      "|[1.6079534655308616,-1.6079534655308616]  |[0.8331270581220072,0.16687294187799284]|0.0       |0        |\n",
      "|[1.58452130928567,-1.58452130928567]      |[0.8298438928687174,0.1701561071312826] |0.0       |0        |\n",
      "|[1.6282317442664058,-1.6282317442664058]  |[0.8359272614555928,0.16407273854440718]|0.0       |0        |\n",
      "|[1.725695881346732,-1.725695881346732]    |[0.8488610479382743,0.15113895206172567]|0.0       |0        |\n",
      "|[1.7117045622022653,-1.7117045622022653]  |[0.8470572430945255,0.15294275690547454]|0.0       |0        |\n",
      "|[1.6557392856244,-1.6557392856244]        |[0.8396652233809373,0.1603347766190627] |0.0       |1        |\n",
      "|[1.6277566473354672,-1.6277566473354672]  |[0.8358620901456201,0.16413790985437993]|0.0       |0        |\n",
      "|[1.628997219068169,-1.628997219068169]    |[0.8360322215304398,0.16396777846956023]|0.0       |0        |\n",
      "|[1.6147145788807267,-1.6147145788807267]  |[0.8340649152045069,0.16593508479549313]|0.0       |0        |\n",
      "|[-0.1335691566991506,0.1335691566991506]  |[0.46665726761992526,0.5333427323800748]|1.0       |1        |\n",
      "|[0.45329429229953444,-0.45329429229953444]|[0.6114221953797232,0.3885778046202768] |0.0       |1        |\n",
      "|[1.6008584802966264,-1.6008584802966264]  |[0.8321383353985411,0.1678616646014589] |0.0       |0        |\n",
      "|[1.461038905511441,-1.461038905511441]    |[0.8116915212498278,0.1883084787501722] |0.0       |0        |\n",
      "|[1.2797666066936948,-1.2797666066936948]  |[0.7824100450998493,0.21758995490015065]|0.0       |0        |\n",
      "|[0.6927569242984926,-0.6927569242984926]  |[0.6665799374130056,0.3334200625869944] |0.0       |1        |\n",
      "|[1.574477592852448,-1.574477592852448]    |[0.8284209879924161,0.17157901200758385]|0.0       |0        |\n",
      "|[1.6444347925532279,-1.6444347925532279]  |[0.8381374774501382,0.16186252254986178]|0.0       |0        |\n",
      "|[1.616554226622049,-1.616554226622049]    |[0.8343193671671436,0.1656806328328564] |0.0       |1        |\n",
      "|[1.5745802691886501,-1.5745802691886501]  |[0.82843558187925,0.17156441812074996]  |0.0       |1        |\n",
      "|[1.742489386448108,-1.742489386448108]    |[0.8510029878441243,0.14899701215587569]|0.0       |0        |\n",
      "|[1.2527932163917852,-1.2527932163917852]  |[0.7777830057653303,0.22221699423466967]|0.0       |1        |\n",
      "|[1.6867475818960944,-1.6867475818960944]  |[0.8437959562342736,0.15620404376572639]|0.0       |0        |\n",
      "|[1.5888083478848296,-1.5888083478848296]  |[0.8304483799043867,0.1695516200956133] |0.0       |0        |\n",
      "|[1.2851091276683213,-1.2851091276683213]  |[0.7833182078874019,0.21668179211259808]|0.0       |0        |\n",
      "|[1.6356682185859794,-1.6356682185859794]  |[0.836944649049261,0.16305535095073898] |0.0       |0        |\n",
      "|[-1.3711981321639977,1.3711981321639977]  |[0.20242633912496333,0.7975736608750367]|1.0       |1        |\n",
      "|[1.6213339073510462,-1.6213339073510462]  |[0.8349790097894192,0.1650209902105808] |0.0       |0        |\n",
      "|[1.6365657982282145,-1.6365657982282145]  |[0.8370671031776787,0.16293289682232126]|0.0       |0        |\n",
      "|[1.6492732962434413,-1.6492732962434413]  |[0.8387928101456477,0.16120718985435234]|0.0       |0        |\n",
      "|[1.5793167005211095,-1.5793167005211095]  |[0.8291077243394168,0.17089227566058318]|0.0       |0        |\n",
      "|[1.1596284643552195,-1.1596284643552195]  |[0.7612651983250529,0.2387348016749471] |0.0       |1        |\n",
      "|[1.7618960087008648,-1.7618960087008648]  |[0.8534469629048828,0.14655303709511724]|0.0       |0        |\n",
      "|[1.6225016347432462,-1.6225016347432462]  |[0.835139846920632,0.16486015307936797] |0.0       |0        |\n",
      "|[1.5946983780534434,-1.5946983780534434]  |[0.8312761054985894,0.16872389450141057]|0.0       |0        |\n",
      "|[1.651029061592499,-1.651029061592499]    |[0.839030082538286,0.16096991746171396] |0.0       |0        |\n",
      "|[1.6513811810278276,-1.6513811810278276]  |[0.8390776336202621,0.1609223663797379] |0.0       |0        |\n",
      "|[-2.3921100517229537,2.3921100517229537]  |[0.0837763265467558,0.9162236734532442] |1.0       |1        |\n",
      "|[1.6235108827302691,-1.6235108827302691]  |[0.8352787544825809,0.16472124551741907]|0.0       |0        |\n",
      "|[1.58091117209456,-1.58091117209456]      |[0.8293335234597954,0.17066647654020461]|0.0       |0        |\n",
      "+------------------------------------------+----------------------------------------+----------+---------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prediction.select(\"rawPrediction\", \"probability\", \"prediction\", \"trueLabel\").show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the results include rows where the probability for 0 (the first value in the probability vector) is only slightly higher than the probability for 1 (the second value in the probability vector). The default discrimination threshold (the boundary that decides whether a probability is predicted as a 1 or a 0) is set to 0.5; so the prediction with the highest probability is always used, no matter how close to the threshold.\n",
    "\n",
    "And we can see from the results above that for those *truelabel* 1s that we predicted 0s, many of them the problibilty of 1 is just slightly less than the threshold 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune Parameters \n",
    "To find the best performing parameters, we can use the **CrossValidator** class to evaluate each combination of parameters defined in a **ParameterGrid** against multiple *folds* of the data split into training and validation datasets. Note that this can take a long time to run because every parameter combination is tried multiple times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the Discrimination Threshold\n",
    "The AUC score seems to indicate a reasonably good model, but the performance metrics seem to indicate that it predicts a high number of *False Negative* labels (i.e. it predicts 0 when the true label is 1), leading to a low *Recall*. We can improve this by lowering the threshold. Conversely, sometimes we may want to address a large number of *False Positive* by raising the threshold. \n",
    "\n",
    "In this case, I'll let the **CrossValidator** find the best threshold from 0.45, 0.4 and 0.35, regularization parameter from 0.3 and 0.1, and the maximum number of iterations allowed from 10 and 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.3, 0.1]).addGrid(lr.maxIter, [10, 5]).addGrid(lr.threshold, \n",
    "                                                                                            [0.4, 0.3]).build()\n",
    "cv = CrossValidator(estimator=pipeline, evaluator=BinaryClassificationEvaluator(), estimatorParamMaps=paramGrid, \n",
    "                    numFolds=2)\n",
    "\n",
    "model = cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+---------+\n",
      "|            features|prediction|trueLabel|\n",
      "+--------------------+----------+---------+\n",
      "|[10.0,1.0,0.0,103...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,103...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,104...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,106...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,107...|       0.0|        1|\n",
      "|[10.0,1.0,0.0,107...|       0.0|        1|\n",
      "|[10.0,1.0,0.0,107...|       0.0|        1|\n",
      "|[10.0,1.0,0.0,107...|       0.0|        1|\n",
      "|[10.0,1.0,0.0,108...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,108...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,108...|       0.0|        1|\n",
      "|[10.0,1.0,0.0,108...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,108...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,110...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,110...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,110...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,110...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,110...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,110...|       0.0|        0|\n",
      "|[10.0,1.0,0.0,110...|       0.0|        0|\n",
      "+--------------------+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newPrediction = model.transform(test)\n",
    "newPredicted = prediction.select(\"features\", \"prediction\", \"trueLabel\")\n",
    "newPredicted.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some of the **rawPrediction** and **probability** values that were previously predicted as 0 are now predicted as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TP</td>\n",
       "      <td>60773.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FP</td>\n",
       "      <td>247.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TN</td>\n",
       "      <td>648540.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FN</td>\n",
       "      <td>100532.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.995952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.376758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F1</td>\n",
       "      <td>0.546704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      metric          value\n",
       "0         TP   60773.000000\n",
       "1         FP     247.000000\n",
       "2         TN  648540.000000\n",
       "3         FN  100532.000000\n",
       "4  Precision       0.995952\n",
       "5     Recall       0.376758\n",
       "6         F1       0.546704"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recalculate confusion matrix\n",
    "tp2 = float(newPrediction.filter(\"prediction == 1.0 AND truelabel == 1\").count())\n",
    "fp2 = float(newPrediction.filter(\"prediction == 1.0 AND truelabel == 0\").count())\n",
    "tn2 = float(newPrediction.filter(\"prediction == 0.0 AND truelabel == 0\").count())\n",
    "fn2 = float(newPrediction.filter(\"prediction == 0.0 AND truelabel == 1\").count())\n",
    "pr2 = tp2 / (tp2 + fp2)\n",
    "re2 = tp2 / (tp2 + fn2)\n",
    "# metrics2 = spark.createDataFrame([\n",
    "#  (\"TP\", tp2),\n",
    "#  (\"FP\", fp2),\n",
    "#  (\"TN\", tn2),\n",
    "#  (\"FN\", fn2),\n",
    "#  (\"Precision\", pr2),\n",
    "#  (\"Recall\", re2),\n",
    "#  (\"F1\", 2*pr2*re2/(re2+pr2))],[\"metric\", \"value\"])\n",
    "# metrics2.show()\n",
    "\n",
    "### Spark data frame is not printing, so using the pandas data frame\n",
    "data = [\n",
    " (\"TP\", tp2),\n",
    " (\"FP\", fp2),\n",
    " (\"TN\", tn2),\n",
    " (\"FN\", fn2),\n",
    " (\"Precision\", pr2),\n",
    " (\"Recall\", re2),\n",
    " (\"F1\", 2*pr2*re2/(re2+pr2))]\n",
    "columns = [\"metric\", \"value\"]\n",
    "pandas_df = pd.DataFrame(data = data, columns = columns)\n",
    "pandas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUR2 =  0.9218255368568777\n"
     ]
    }
   ],
   "source": [
    "# Recalculate the Area Under ROC\n",
    "evaluator2 = BinaryClassificationEvaluator(labelCol=\"trueLabel\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "aur2 = evaluator.evaluate(prediction)\n",
    "print( \"AUR2 = \", aur2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty good! The new model improves the *Recall* from 0.11 to 0.37, the *F1* score from 0.20 to 0.54, without compromising other metrics.\n",
    "\n",
    "## Next Step\n",
    "\n",
    "There is still much room to improve the model. For example, I can try more options of lower threshold, or use different classfication models, or prepare data better like adding new features. I'll write another one for this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
